# Language 语言
*- 项目分枝：
  - Parser 解释器/编译器（项目主要解决‘语法结构的分析’，而不是‘语义’的判断）
  - Attention 注意力机制（？？？）*

## Attention
语义定义：
- mask：可翻译成"遮罩"和"掩码"；
- token：可翻译为"标记"或"令牌"；
- tokenizer：令牌生成器、分词器（hugging face官网的教程里，就是中文翻译成‘分词器’）
- 不影响**语义**。  
### 题干
编写一个人工智能来预测文本序列中的屏蔽词。
```zsh
$ python mask.py
Text: We turned down a narrow lane and passed through a small [MASK].
We turned down a narrow lane and passed through a small field.
We turned down a narrow lane and passed through a small clearing.
We turned down a narrow lane and passed through a small park.

$ python mask.py
Text: Then I picked up a [MASK] from the table.
Then I picked up a book from the table.
Then I picked up a bottle from the table.
Then I picked up a plate from the table.
```
#### 背景   
创建语言模型的一种方法是建立掩码/遮罩语言模型（Masked Language Model），即训练语言模型来预测文本序列中缺少的 “掩码/遮罩”单词。BERT是谷歌开发的一种基于**转换器transformer**的语言模型，它就是用这种方法训练出来的：根据周围的 *上下文词语* ，训练语言模型来预测一个屏蔽词/遮罩词。  
BERT 采用**转换器架构 transformer architecture**，因此使用**注意力机制 attention**来理解语言。在基础 BERT 模型中，转换器使用 12 层，每层有 12 个自我注意头，总共有 144 个自我注意头。  
本项目包括两个部分：  
首先，我们将使用人工智能软件公司 Hugging Face 开发的**Transformer Python library 转换器py库**，编写一个使用 BERT 预测屏蔽词的程序。该程序还将生成可视化注意力得分图表，144 个注意力头各生成一个图表。  
其次，我们将对程序生成的图表进行分析，试图 *（目标之一：）了解 BERT 的注意力头在试图理解我们的自然语言时可能会关注哪些内容*。  
#### 理解  
首先来看一下 mask.py 程序。在主函数（main function）中，首先会提示用户输入一些文本。输入文本应包含一个遮罩标记 [MASK]（a mask token[MASK]），代表我们的语言模型应尝试预测的单词。然后，本函数（function）会**使用自动标记器（AutoTokenizer）将输入内容分割成标记（tokens）**。  

在 BERT 模型中，每个不同的标记（token）都有自己的 ID 号。其中一个 ID 由 **tokenizer.mask_token_id** 提供，对应于 [MASK] 标记。大多数其他标记代表单词，但也有一些例外。[CLS] 标记总是出现在文本序列的开头。[SEP]标记出现在文本序列的末尾，用于分隔序列。有时，一个单词会被拆分成多个标记：例如，BERT 将单词 “intelligently ”视为两个标记：intelligent 和 ##ly。  

接下来，我们使用 **[`TFBertForMaskedLM`](https://huggingface.co/docs/transformers/v4.31.0/en/model_doc/bert#transformers.TFBertForMaskedLM)** 做实例，使用 BERT 语言模型预测一个被屏蔽的标记。输入标记（inputs）被传入模型，然后我们寻找前 K 个输出标记（output tokens）。原始序列被打印出来，屏蔽标记被每个预测输出标记替换（参考上面的zsh部份代码举例）。  

最后，程序调用 visualize_attentions 函数，该函数将为 BERT 的每个注意力头（attention heads）生成输入序列的注意力值（attention values）图。  

大部分代码已经为您编写完成，但 get_mask_token_index、get_color_for_attention_score 和 visualize_attentions 的实现则需要您自己完成！  

完成这三个函数后，mask.py 程序就会生成注意力图。通过这些图，我们可以了解 BERT 在理解语言时需要注意的事项。例如，下面是第 3 层第 10 个头在处理句子 “然后我从桌子上拿起了一个 [MASK]”时的注意图。  

![image](https://github.com/HanhanXing/-2024/assets/49121375/abcdc534-6ae0-433e-a6b8-a77ffcaabafb)  

回想一下，浅色代表较高的注意力权重（attention weight），深色代表较低的注意力权重。在这种情况下，这个注意头似乎已经学会了一个非常清晰的模式：每个单词都在注意紧随其后的单词。例如，“then ”这个词在图中的第二行中，最亮的单元格是与 “i ”列相对应的单元格，这表明 “then ”这个词对 “i ”这个词的注意力很强（attending strongly to）。句子中的其他标记（tokens）也是如此。  

您可以尝试在其他句子中运行 mask.py，以验证第 3 层第 10 个头是否继续遵循这种模式。从直觉上讲（intuitively），BERT 有可能学会识别这种模式：理解一连串文本中的某个单词往往取决于知道下一个单词是什么，因此有一个（或多个）注意力头专门关注下一个单词是什么可能很有用。   

这个注意头特别清晰，但通常注意头会比较嘈杂（noisier），可能需要更多的解释才能猜出 BERT 可能在注意什么。  

比如说，我们很想知道 BERT 是否关注副词的作用。我们可以给这个模型一个句子，比如 “乌龟慢慢地穿过[MASK]”，然后观察所得到的注意头，看看语言模型是否注意到 “慢慢地 ”是修饰 “moved ”的副词。在得到的注意力图中，第 4 层第 11 个头可能会引起您的注意。  

![image](https://github.com/HanhanXing/-2024/assets/49121375/5cef996d-a34a-45d1-a28e-d24019b68d02)  

这个注意头肯定比较嘈杂：这个注意头到底在做什么并不是一眼就能看出来的。但是请注意，对于副词 “慢慢地”，它最关注的是它所修饰的动词： “移动”。如果我们调换动词和副词的顺序，情况也是一样。  
![image](https://github.com/HanhanXing/-2024/assets/49121375/8147c257-527e-4a8c-b100-b3107cf6b332)  

甚至在副词和它所修饰的动词没有直接挨在一起的句子中也是如此。  
![image](https://github.com/HanhanXing/-2024/assets/49121375/24b87218-1fea-40b5-a560-991b6b4c109f)  

因此，我们有理由猜测（reasonably guess），这个注意头已经学会了注意副词和它们修饰的词之间的关系。注意层并不总是与我们对单词间特定关系的预期一致，**也并不总是与人类可解释的（human-interpretable）关系完全一致**，但我们可以根据它们看起来的对应关系进行猜测--至少在这个项目中，你得这么做！  

#### 规则
首先，完成 `get_mask_token_index`、`get_color_for_attention_score` 和 `visualize_attentions` 的实现。  

- `get_mask_token_index` 函数**接受**2个东西：1) 遮罩标记的ID *（**mask token ID**）*，以`int`表示；和 2) 令牌生成器/分词器（tokenizer）生成的 **`input`**，类型为 transformers.BatchEncoding。它将返回遮罩标记（mask token）在输入（`input`）标记序列（sequence of tokens）中的索引(index)。  
  - 索引应为 **"0-indexed"**（从0开始计数））。例如，如果第三个input ID 是 mask token ID，那么函数应返回‘2’。  
  - 如果输入序列中根本没有mask token，则函数应返回 None。  
  - 您可以假设`input`序列中不会有超过一个的mask token。  
  - 自助探索：查看**Transformer 转换器**的文档，特别是 **[调用Tokenizer(分词器)的返回值](https://huggingface.co/docs/transformers/main/zh/main_classes/tokenizer)**，以了解 `BatchEncoding` 具有哪些你可能想要访问的字段。  
- `get_color_for_attention_score` 函数应**接受**一个注意力分数（介于 0 和 1 之间的数值，包括 0 和 1），并**输出**一个由三个整数组成的元组（tuple），代表一个 *RGB三元组-RGB Triple*（一个红色值、一个绿色值、一个蓝色值），作为注意力图中该注意力单元的颜色。  
  - 如果注意力分数为 0，则颜色应为全黑（值 (0,0,0)）。如果注意力分数为 1，则颜色应为全白（值（255, 255, 255））。对于介于两者之间的注意力分数，颜色应为与注意力分数成线性比例的灰色。  
  - 要使颜色成为灰色，红色、蓝色和绿色的值都应相等。  
  - 红、绿、蓝值必须都是整数，但可以选择截断(truncate)或四舍五入(round)。例如，对于注意力分数 0.25，函数可以返回 (63, 63, 63) 或 (64, 64, 64)，因为 255 的 25% 是 63.75。  
- 函数 `visualize_attentions` **接受**整个`tokens`序列（一个字符串列表）和`attention`，后者包含模型生成的所有注意力分数。对于每个注意力头，函数应生成一个注意力可视化图表，如调用 generate_diagram。  
  - `attentions` 值是一个 *张量元组 tuple of tensors*（“张量 tensor”在这里可以看作是一个多维数组）。
  - 要对 `attentions` 值进行索引以获取特定注意力头的值，可以使用 `attentions[i][j][k]`，其中 `i` 是注意力层(layer)的索引，`j` 是波束数(beam number)的索引（在我们的例子中总是 `0`），`k` 是层中注意力头(attention head)的索引。
  - 这个函数包含一个现有的实现，它只为第一个注意力层中的第一个注意力头生成一个注意力图。您的任务是扩展这个实现，为所有注意头和注意层生成图表。
  - `generate_diagram` 函数的前两个输入必须是layer index层号和head index头部号。这些号数应该是“1-indexed”。换句话说，对于第一个注意头和注意层（每个注意头和注意层的索引都是 `0`），`layer_number` 应该是 `1`，`head_number` 也应该是 `1`。  

完成上述三个函数后，您就可以运行 `mask.py` 来预测屏蔽词并生成注意力图。本项目的第二部分是分析您所选句子的注意图，以推断特定注意头在语言理解过程中扮演的角色。您将在 `analysis.md` 中填写您的分析结果。  
- 完成 analysis.md 中的 TODO。
  - 您应该描述至少两个注意头，您已经确定了注意头似乎已经学会的单词之间的某些关系。在每种情况下，请写一两句话描述注意头似乎在注意什么，并给出至少两个您输入模型以得出结论的例句。
  - 本项目说明的 “理解 ”部分为您提供了两个示例： 在第 3 层第 10 个词头中，标记词似乎会关注其后面的标记词；在第 4 层第 11 个词头中，副词似乎会关注其所修饰的动词。您所识别的语言方面应不同于这两个方面。
  - 注意头可能是嘈杂的，因此它们并不总是有明确的人类解释。有时，它们关注的可能不仅仅是您所描述的关系，有时，它们不会在每个句子中都识别出您所描述的关系。这没有关系！这里的目的是根据我们人类对语言的直觉来推断注意力，而不一定要确定每个注意力头的确切作用。
  - 您可以寻找您感兴趣的词语之间的任何关系。如果要寻找思路，您可以考虑以下任何一种：动词与其直接宾语、介词、代词、形容词、定语之间的关系，或者注意前面的标记。

#### Hints
在分析图时，经常会发现许多attention heads中的许多tokens都倾向于强烈地注意 [SEP] token或 [CLS] token。这情况可能发生在某个attention head中没有好词（或说是token）可注意的情况下。



### 代码和代码结构
### 分段解读
### 最终成品
### 其他问题/经验备注

## Parser
### 题干
### 代码和代码结构
### 分段解读
### 最终成品
### 其他问题/经验备注
